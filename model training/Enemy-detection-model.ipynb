{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0a6447",
   "metadata": {},
   "source": [
    "# Enemy detection model - YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6e886",
   "metadata": {},
   "source": [
    "This notebook will be used to train a convolutional neural network (CNN) model using [YOLOv5](https://github.com/ultralytics/yolov5).\n",
    "\n",
    "The model generated by the YOLO algorithm will serve the purpose of detecting enemies in real-time in the first map of the game [Dusk's](https://store.steampowered.com/app/519860/DUSK/) Endless mode (The Farm). The model should be able to detect the five different types of enemies present on the map.\n",
    "\n",
    "To keep up with Dusk's frantic pace, a model that is both accurate and fast enough is needed. Therefore, YOLOv5 was chosen for being a good compromise between accuracy and speed compared to other YOLO versions, at least on normal GPU systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e3e85",
   "metadata": {},
   "source": [
    "## 1. First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a465ac0",
   "metadata": {},
   "source": [
    "### 1.1 Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c984a75",
   "metadata": {},
   "source": [
    "This subsection will be helpful if you plan on running this notebook on Google Colab. Otherwise, skip to subsection 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e291f",
   "metadata": {},
   "source": [
    "First, upload this notebook under the desired directory of your Google Drive account.\n",
    "\n",
    "After doing that, execute the following cell to connect your Drive account to Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fedc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a04fc2",
   "metadata": {},
   "source": [
    "After that, insert the path where this notebook was saved in your Drive account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aadc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NOTEBOOK_PATH = 'dusk-aimbot/model training' # CAN BE CHANGED\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', NOTEBOOK_PATH)\n",
    "\n",
    "%cd ./$GOOGLE_DRIVE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6524619",
   "metadata": {},
   "source": [
    "### 1.2 Clone YOLOv5 repository and import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d5a857",
   "metadata": {},
   "source": [
    "To start, place this notebook under the desired directory and clone the YOLOv5 Github repository from Ultralytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904c78c",
   "metadata": {},
   "source": [
    "Install the packages required by YOLOv5 with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f043e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4097d29f",
   "metadata": {},
   "source": [
    "Change the current working directory to `yolov5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee09571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'yolov5'\n",
      "/home/leleo/dusk-aimbot/model training/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924f305",
   "metadata": {},
   "source": [
    "Don't forget to import all the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7059e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from yolov5 import utils\n",
    "import torch\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(108)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29446004",
   "metadata": {},
   "source": [
    "## 2. Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9d9b9",
   "metadata": {},
   "source": [
    "### 2.1 Organize Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3168f6",
   "metadata": {},
   "source": [
    "[According to the YOLOv5 wiki](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data), it is recommended to organize the data inside a `/datasets` directory next to the `/yolov5` directory, as represented below:\n",
    "\n",
    "![data_directory_structure](https://miro.medium.com/max/1400/1*J2UTo9Z2hJCeaTwB1d_aNw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a22984",
   "metadata": {},
   "source": [
    "The following function will generate data subdirectories splitted into train, val, and test inside `/datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_directories(data_name):\n",
    "    Path(f\"../datasets/{data_name}/images/train\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"../datasets/{data_name}/images/valid\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"../datasets/{data_name}/images/test\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"../datasets/{data_name}/labels/train\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"../datasets/{data_name}/labels/valid\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"../datasets/{data_name}/labels/test\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7856678",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data_directories('dusk_enemies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8594b",
   "metadata": {},
   "source": [
    "### 2.2 Organize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724b35c",
   "metadata": {},
   "source": [
    "Our data directories were generated, but we still need to split our data and move it there.\n",
    "Thus, create a `/image_data` directory next to the `/datasets` and `/yolov5` directories.\n",
    "\n",
    "Inside this directory, create: \n",
    "1. `/background_images` for images without YOLO labels;\n",
    "2. `/labeled_images` for images with YOLO labels related to them;\n",
    "3. `/labels` for YOLO labels (.txt files) related to those images in `/labeled_images`.\n",
    "\n",
    "as shown below:\n",
    "```bash\n",
    ".\n",
    "├── yolov5/\n",
    "├── datasets/\n",
    "└── image_data/\n",
    "    ├── background_images/\n",
    "    ├── labeled_images/\n",
    "    └── labels/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511401b",
   "metadata": {},
   "source": [
    "Background images are separated from labeled images because they are split in a different manner.\n",
    "\n",
    "However, if you have all your images in a single folder, put all of them inside `/labeled_images` and run the following cell to create `/background_images` automatically and move your background images inside it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6c898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMG_PATH = \"../image_data/labeled_images\"\n",
    "LABEL_PATH = \"../image_data/labels\"\n",
    "BACKGROUND_PATH = \"../image_data/background_images\"\n",
    "\n",
    "# Creates a directory for background images if it doesn't exist\n",
    "Path(BACKGROUND_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bg_count = 0\n",
    "for image in glob.iglob(f\"{IMG_PATH}/*.jpeg\"):\n",
    "\n",
    "    # Gets image name\n",
    "    name = image.split(IMG_PATH)[1].split(\".jpeg\")[0]\n",
    "    \n",
    "    # Checks if there is a correspondent txt label file related to the image\n",
    "    label_exists = os.path.isfile(f\"{LABEL_PATH}/{name}.txt\")\n",
    "    \n",
    "    # If the label doesn't exist, the image is a background image (no labels related to it)\n",
    "    if not label_exists:\n",
    "        try: # Move background image to an appropriate directory\n",
    "            bg_count += 1\n",
    "            shutil.move(image, BACKGROUND_PATH)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "print(f\"\\n{bg_count} background images moved from \\\"{IMG_PATH}\\\" to \\\"{BACKGROUND_PATH}\\\".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6e3d6",
   "metadata": {},
   "source": [
    "### 2.3 Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fe736",
   "metadata": {},
   "source": [
    "After generating data directories, our data should be split and moved to their respective directories.\n",
    "\n",
    "For this model, the train, validation, and test sets will contain 80%, 10%, and 10% of the data, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1734017",
   "metadata": {},
   "source": [
    "To make sure that each labeled image and its label is split into the same group, labeled and background images will be split separately.\n",
    "\n",
    "First, the set of labeled images will be split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bafd58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Code adapted from https://blog.paperspace.com/train-yolov5-custom-data/\n",
    "\n",
    "IMG_PATH = \"../image_data/labeled_images\"\n",
    "LABEL_PATH = \"../image_data/labels\"\n",
    "\n",
    "# Read images and labels\n",
    "images = [os.path.join(IMG_PATH, x) for x in os.listdir(IMG_PATH)]\n",
    "labels = [os.path.join(LABEL_PATH, x) for x in os.listdir(LABEL_PATH) if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "labels.sort()\n",
    "\n",
    "# Split the dataset into train / valid / test splits \n",
    "train_images, remain_images, train_labels, remain_labels = train_test_split(images, labels, train_size = 0.8, random_state = 1)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(remain_images, remain_labels, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77903b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code adapted from https://blog.paperspace.com/train-yolov5-custom-data/\n",
    "\n",
    "# Utility function to move images to their respective directory\n",
    "def move_files_to_directory(list_of_files, destination_dir):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_dir)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_IMG_PATH = '../datasets/dusk_enemies/images'\n",
    "DATASET_LABEL_PATH = '../datasets/dusk_enemies/labels'\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_directory(train_images, f'{DATASET_IMG_PATH}/train/')\n",
    "move_files_to_directory(val_images, f'{DATASET_IMG_PATH}/valid/')\n",
    "move_files_to_directory(test_images, f'{DATASET_IMG_PATH}/test/')\n",
    "move_files_to_directory(train_labels, f'{DATASET_LABEL_PATH}/train/')\n",
    "move_files_to_directory(val_labels, f'{DATASET_LABEL_PATH}/valid/')\n",
    "move_files_to_directory(test_labels, f'{DATASET_LABEL_PATH}/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a95917",
   "metadata": {},
   "source": [
    "This time, we will use slicing to split background images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_IMG_PATH = \"../image_data/background_images\"\n",
    "\n",
    "# Read images and labels\n",
    "bg_images = [os.path.join(BG_IMG_PATH, x) for x in os.listdir(BG_IMG_PATH)]\n",
    "\n",
    "random.shuffle(bg_images) # Shuffle background images' list to guarantee randomness\n",
    "\n",
    "bg_80_percent = int(0.8 * len(bg_images))\n",
    "bg_90_percent = int(0.9 * len(bg_images))\n",
    "\n",
    "train_bg_images = bg_images[:bg_80_percent] # The first 80% of background images is the train set\n",
    "val_bg_images = bg_images[bg_80_percent : bg_90_percent] # The 10% between 80~90% is the validation set\n",
    "test_bg_images = bg_images[bg_90_percent:] # The last 10% is the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71671466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_BG_PATH = '../datasets/dusk_enemies/images'\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_directory(train_bg_images, f'{DATASET_BG_PATH}/train/')\n",
    "move_files_to_directory(val_bg_images, f'{DATASET_BG_PATH}/valid/')\n",
    "move_files_to_directory(test_bg_images, f'{DATASET_BG_PATH}/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ec912",
   "metadata": {},
   "source": [
    "### 2.4 Create dataset.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbbf04c",
   "metadata": {},
   "source": [
    "A dataset config file (YAML file) should also be created. It defines:\n",
    "\n",
    "1. the dataset root directory `path` and relative paths to `train` / `val` / `test` image directories;\n",
    "2. the number of classes `nc` that you want to detect;\n",
    "3. and the names corresponding to those classes, represented by `names`.\n",
    "\n",
    "YAML files are commonly created inside `/yolov5/data`, and so will be ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941e0dc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat data/dusk_enemies.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4c3e2",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f1500",
   "metadata": {},
   "source": [
    "Because our dataset is quite small, we will use the YOLOv5s model to start training from pretrained weights.\n",
    "\n",
    "The training parameters may be changed as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 1280 --batch 16 --epochs 150\\\n",
    "    --data 'data/dusk_enemies.yaml' --weights 'yolov5s.pt'\\\n",
    "    --project 'dusk_runs' --name 'enemy_detection_train'\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3a739",
   "metadata": {},
   "source": [
    "If the training stops for whatever reason, run `train.py` with the `--resume` flag to resume it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --resume\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764097f6",
   "metadata": {},
   "source": [
    "If Google Colab is used, the `plot_results` function can be used to plot the training results in CSV to a PNG image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e817b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_results\n",
    "\n",
    "# CSV to PNG\n",
    "CSV_RESULTS_PATH = \"\"\n",
    "plot_results(CSV_RESULTS_PATH)\n",
    "\n",
    "# Shows the resulting plots\n",
    "PNG_RESULTS_PATH = \"\"\n",
    "display.Image(PNG_RESULTS_PATH, width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc080e2e",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d026c05",
   "metadata": {},
   "source": [
    "The validation script will be used to evaluate the trained model. The `--task` flag controls which dataset partition will be used on the validation process.\n",
    "\n",
    "Below, the model performance is evaluated over the test partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c023875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py --weights './dusk_runs/enemy_detection_train2/weights/best.pt' --batch 32\\\n",
    "    --data 'data/dusk_enemies.yaml' --task test\\\n",
    "    --project 'dusk_runs' --name 'validation_on_test_data'\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94914092",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853778cd",
   "metadata": {},
   "source": [
    "Finally, the model can be used for inference having different sources as input.\n",
    "\n",
    "Below, the inference occurs with a video and confidence threshold of 0.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_VIDEO = \"\"\n",
    "PATH_TO_MODEL = \"\"\n",
    "\n",
    "!python detect.py --weights PATH_TO_MODEL --img 1280 --conf 0.7\\\n",
    "    --source PATH_TO_VIDEO\\\n",
    "    --project 'dusk_runs' --name 'detect_test'\n",
    "\n",
    "clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
